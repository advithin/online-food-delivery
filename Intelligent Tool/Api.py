from flask import Flask, render_template, request
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.base import BaseEstimator, TransformerMixin
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.model_selection import train_test_split, cross_val_score, cross_validate, GridSearchCV, learning_curve
from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet, LogisticRegression
from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import mean_squared_error, accuracy_score
import time
import warnings
import pickle
warnings.filterwarnings('ignore')
# Class for filtering data
class AttrSelect(BaseEstimator, TransformerMixin):
    
    def __init__(self, cols):
        self.cols = cols
    
    def fit(self, X, y=None):
        return self
    
    def transform(self, X, y=None):
        
        return X.loc[:, cols]
    
# Class for making more preparation
class TransformData(BaseEstimator, TransformerMixin):
    
    def __init__(self, new_data=False):
        self.new_data = new_data
    
    def fit(self, X, y=None):
        return self
    
    def transform(self, X, y=None):
        # Transforming approx_cost column
        X['approx_cost(for two people)'] = X['approx_cost(for two people)'].astype(str)
        X['approx_cost(for two people)'] = X['approx_cost(for two people)'].apply(lambda x: x.replace(',', '.'))
        X['approx_cost(for two people)'] = X['approx_cost(for two people)'].astype(float)
        
        if not self.new_data:        
            # Transforming rate column
            X['rate'] = X['rate'].astype(str)
            X['rate'] = X['rate'].apply(lambda x: x.split('/')[0])
            X['rate'] = X['rate'].apply(lambda x: x.replace('NEW', str(np.nan)))
            X['rate'] = X['rate'].apply(lambda x: x.replace('-', str(np.nan)))
            X['rate'] = X['rate'].astype(float)
        
        return X

# Class for dealing with null data
class DropNull(BaseEstimator, TransformerMixin):
    
    def fit(self, X, y=None):
        return self
    
    def transform(self, X, y=None):
        return X.dropna()
    
# Separating data into training and test
class SplitData(BaseEstimator, TransformerMixin):
    
    def __init__(self, target_col='rate'):
        self.target_col = target_col
    
    def fit(self, X, y=None):
        return self
    
    def transform(self, X, y=None):
        features = X.drop([self.target_col], axis=1)
        target = X.loc[:, [self.target_col]]
        
        return train_test_split(features, target, test_size=.20, random_state=42)

#Function for creating dataset
def create_dataset():
    """
    This functions creates a pandas DataFrame for receiving performance analysis
    
    Returns:
        An empty pandas DataFrame object with regression metrics to be evaluated
    """
    attributes = ['model', 'rmse_train', 'rmse_cv', 'rmse_test', 'total_time']
    model_performance = pd.DataFrame({})
    for col in attributes:
        model_performance[col] = []
    return model_performance


#Function to evaluate model
def model_results(models, X_train, y_train, X_test, y_test, df_performance, cv=10, 
                  scoring='neg_mean_squared_error'):
    """
    This function brings up a full model evaluation and saves it in a DataFrame object
    
    Input:
        model: a dictionary with regression models
        X_train, y_train, X_test, y_test: data to be evaluated
        df_performance: an empty dataframe (generated by crate_dataset() function)
        cv: cross validation k folds
        
    Returns:
        A DataFrame object with all metrics from all models on classifier's dictionary.
    """
    for name, model in models.items():
        t0 = time.time()
        model.fit(X_train, y_train)
        train_pred = model.predict(X_train)
        train_mse = mean_squared_error(y_train, train_pred)
        train_rmse = np.sqrt(train_mse)

        train_cv_scores = cross_val_score(model, X_train, y_train, cv=cv, scoring=scoring)
        train_cv_rmse = np.sqrt(-train_cv_scores).mean()

        test_pred = model.predict(X_test)
        test_mse = mean_squared_error(y_test, test_pred)
        test_rmse = np.sqrt(test_mse)
        t1 = time.time()
        delta_time = t1-t0
        model_name = model.__class__.__name__

        performances = {}
        performances['model'] = model_name
        performances['rmse_train'] = round(train_rmse, 4)
        performances['rmse_cv'] = round(train_cv_rmse, 4)
        performances['rmse_test'] = round(test_rmse, 4)
        performances['total_time'] = round(delta_time, 3)
        df_performance = df_performance.append(performances, ignore_index=True)
        
    return df_performance

#Function to calculate root mean square error
def calc_rmse(model, X, y, cv=5, scoring='neg_mean_squared_error'):
    """
    This functions is responsible for calculatin the root mean squared error for a model
    
    Input:
        model: a regression model
        X, y: features and target
        cv: cross validation k fold
        scoring: scoring to be evaluated (default: neg_mean_squared_error)
        
    Output:
        rmse: root mean squared error
    """
    scores = cross_val_score(model, X, y, cv=cv, scoring=scoring)
    
    return np.sqrt(-scores).mean()

#Loading data    
df = pd.read_csv('zomato.csv')
cols = ['online_order', 'book_table', 'votes', 'approx_cost(for two people)', 
                'listed_in(type)', 'listed_in(city)', 'rate']

#Checking attribute selector class
attr_selector = AttrSelect(cols=cols)
df_selected = attr_selector.fit_transform(df)
print(df_selected.head())

#Checking transformer class
data_transformer = TransformData()
df_transformed = data_transformer.fit_transform(df_selected)
print(df_transformed.head())

# Trying the class
null_dropper = DropNull()
df_prepared = null_dropper.fit_transform(df_transformed)
print(f'Data dimensions after handling null data: {df_prepared.shape}\n')
print('Null data:\n')
print(df_prepared.isnull().sum())

data_splitter = SplitData()
X_train, X_test, y_train, y_test = data_splitter.fit_transform(df_prepared)

print(f'X_train dimension: {X_train.shape}')
print(f'y_train dimension: {y_train.shape}')
print(f'\nX_test dimension: {X_test.shape}')
print(f'y_test dimension: {y_test.shape}')

#Making pipeline
# Defining a pipeline
num_attribs = ['votes', 'approx_cost(for two people)']
cat_attribs = ['online_order', 'book_table', 'listed_in(type)', 'listed_in(city)']
all_attribs = num_attribs + cat_attribs
X_num = X_train.loc[:, num_attribs]
X_cat = X_train.loc[:, cat_attribs]

# Common pipeline
common_pipeline = Pipeline([
    ('attr_selector', AttrSelect(all_attribs)),
    ('data_transformer', TransformData()),
    ('null_dropper', DropNull()),
    ('data_splitter', SplitData())
])

# Numerical pipeline
num_pipeline = Pipeline([
    ('scaler', StandardScaler()),
])

# Categorical pipeline
cat_pipeline = Pipeline([
    ('one_hot', OneHotEncoder(sparse=False)),
])

# Full pipeline
full_pipeline = ColumnTransformer([
    ('num', num_pipeline, num_attribs),
    ('cat', cat_pipeline, cat_attribs),
])

# Applying pipelines
X_train, X_test, y_train, y_test = common_pipeline.fit_transform(df)

X_train_prepared = full_pipeline.fit_transform(X_train)
X_test_prepared = full_pipeline.fit_transform(X_test)

app = Flask(__name__)
prediction=""
@app.route('/predict', methods=['POST'])
def predict():
    final_model=pickle.load(open('Final_model.sav','rb'))
    test=list()
    tup=list()
    tup.append(request.form['online'])
    tup.append(request.form['book'])
    tup.append(request.form['vote'])
    tup.append(request.form['approx'])
    tup.append(request.form['type'])
    tup.append(request.form['location'])
    test.append(tuple(tup))
    test_df=pd.DataFrame(test,columns=['online_order','book_table','votes','approx_cost(for two people)','listed_in(type)','listed_in(city)'])
    test_check=full_pipeline.transform(test_df)
    prediction=final_model.predict(test_check)
    print(prediction)
    return '<body style="background-image:linear-gradient(to bottom right,black,violet);color:white;font-size:25px;"><br><br><br><br><center>The predicted rank of %s is %lf/5</center></body>' % (request.form['name'], prediction[0])

if __name__ == '__main__':
    app.run(host = '127.0.0.1', port = 3000)